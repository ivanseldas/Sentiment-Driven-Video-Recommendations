{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 02:29:04 WARN Utils: Your hostname, DESKTOP-AEUBGUH resolves to a loopback address: 127.0.1.1; using 172.20.208.1 instead (on interface eth1)\n",
      "24/09/25 02:29:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 02:29:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.read_parquet(\"../data/clean_data/df_comments_video.parquet\")\n",
    "df = spark.createDataFrame(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 02:29:25 WARN TaskSetManager: Stage 0 contains a task of very large size (4578 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+----------+-------------------+-------------------+---------------+-----------+--------------------+\n",
      "|          comment_id|              author|   author_channel_id|                text|like_count|       published_at|         updated_at|totalReplyCount|   video_id|          clean_text|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+-------------------+-------------------+---------------+-----------+--------------------+\n",
      "|UgxqJ2eO2p7w2NEvB...|  @emmanuelamama1991|UCdUooL3DTt3Wj0M3...|great video,helpful.|       1.0|2024-08-17 15:07:48|2024-08-17 15:07:48|            1.0|qtlUwwtvuEg|  great videohelpful|\n",
      "|UgzmXwaNzivNHqjfR...|   @dr.alexshayo6972|UCN56M0YoTn18rd_K...|Thank you for suc...|       4.0|2023-05-01 16:48:21|2023-05-01 16:48:21|            1.0|qtlUwwtvuEg|thank well explai...|\n",
      "|UgyySzt4xOZ1hKdS9...|     @mohdkashif4596|UCr5Ua5AsmM6phaRu...|very useful tools...|       2.0|2023-07-20 13:33:23|2023-07-20 13:33:23|            1.0|qtlUwwtvuEg|useful tool thank...|\n",
      "|UgyHVo-IOZw_-uLb-...|          @pipedrmmr|UC5KmDvJCDtoM31gj...|This is great inf...|      13.0|2023-06-25 02:36:50|2023-06-25 02:36:50|            1.0|qtlUwwtvuEg|great information...|\n",
      "|UgyIT65ucXCc-4loB...|        @anamnaz2527|UCriCWejgmnsDkaX7...|first two are not...|       1.0|2023-05-31 18:41:21|2023-05-31 18:41:21|            1.0|qtlUwwtvuEg|first two goof ai...|\n",
      "|UgwTD-F3eXXyuu69D...|     @naginakhan2814|UCZl0m7mBgEYH2pDt...|         Informative|       2.0|2023-08-05 20:58:19|2023-08-05 20:58:19|            1.0|qtlUwwtvuEg|         informative|\n",
      "|Ugwb-J02-9hQgzhml...|@enriquetabuenave...|UCLXTa307tK48oFZO...|I am 66 years old...|       3.0|2023-08-03 16:52:57|2023-08-03 16:52:57|            1.0|qtlUwwtvuEg|year old elementa...|\n",
      "|UgxwacAhzSdfyuqop...|          @jocareers|UC1rhe70J35q1th81...|more informative ...|       1.0|2023-06-23 08:26:51|2023-06-23 08:26:51|            1.0|qtlUwwtvuEg|informative aweso...|\n",
      "|UgxYGoNCpHvUwiFxw...|@nongnitteerawata...|UCajwhzRIoFYkJWVf...|Thanks for creati...|       1.0|2023-07-16 10:56:53|2023-07-16 10:56:53|            1.0|qtlUwwtvuEg|thanks creating s...|\n",
      "|UgxqkhcAmRdtlnchF...|        @1234sanarch|UCHSS7VPbU3txzUU3...|nice narration an...|       1.0|2023-06-19 03:05:39|2023-06-19 03:05:39|            3.0|qtlUwwtvuEg|nice narration pr...|\n",
      "|Ugxae5qs4-GsWyaF7...|@theophilusnyamek...|UCS6uwyc2Y3EnZbr1...|             Awesome|       1.0|2024-07-31 17:39:21|2024-07-31 17:39:21|            1.0|qtlUwwtvuEg|             awesome|\n",
      "|UgxgI6faSG-6Vqy1K...|    @JeevaSivalingam|UCy4QtnmMw4IrlqTQ...|ultimate information|       1.0|2023-07-04 20:40:29|2023-07-04 20:40:29|            1.0|qtlUwwtvuEg|ultimate information|\n",
      "|UgyETrIoVq1uyNhqe...|    @user-kh6yb6fq1e|UCeZ4h2QX_U_denW5...|it was helpful th...|       1.0|2023-11-17 02:38:53|2023-11-17 02:38:53|            1.0|qtlUwwtvuEg|helpful thanks sh...|\n",
      "|Ugw-ImXZM3YC1bjE2...|    @anshumandas6186|UCj3Np9sLesTQk2M-...|It is very good v...|       1.0|2024-05-11 08:22:51|2024-05-11 08:22:51|            1.0|qtlUwwtvuEg|good video writin...|\n",
      "|Ugw8VtwWT_XGhngY5...|      @creatorsmafia|UCwKExl7Lfmf8bsx6...|AI is making rese...|      18.0|2023-06-14 16:19:12|2023-06-14 16:19:12|            3.0|qtlUwwtvuEg|ai making researc...|\n",
      "|Ugxp0B3hJtO2jk8ww...|          @alibli197|UCv7WskQKUWiAqhw3...|      important one.|       2.0|2024-07-02 19:51:31|2024-07-02 19:51:31|            1.0|qtlUwwtvuEg|       important one|\n",
      "|UgyveZ7j4whsFAHvt...|@asiimwejohnpatri...|UCEi5Jrnp_r0yLQLc...|this awesome. thanks|       1.0|2024-08-01 17:39:29|2024-08-01 17:39:29|            1.0|qtlUwwtvuEg|      awesome thanks|\n",
      "|UgzWMNjo6Plllt0_c...|@GetachewBelay-wf1qs|UCAy4bLCBb_8gK3SC...|Best presention a...|       1.0|2023-09-12 14:16:14|2023-09-12 14:16:14|            1.0|qtlUwwtvuEg|best presention h...|\n",
      "|UgwIFjIHU5cc3x3qA...|        @PhoneNayZin|UCuOqD8mvpXeqkUzu...|Thanks for sharin...|       1.0|2024-04-24 00:17:51|2024-04-24 00:17:51|            1.0|qtlUwwtvuEg|thanks sharing in...|\n",
      "|UgwqDD8mTKQfe1k3g...|@ramlahbintimailo...|UCPS4dmnveh9UOgn-...|This great inform...|       1.0|2023-10-11 05:31:27|2023-10-11 05:31:27|            1.0|qtlUwwtvuEg|great information...|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+-------------------+-------------------+---------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivanseldasp/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "sentiment_model = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    try:\n",
    "        sentiment = sentiment_model(text)\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "sentiment_udf = udf(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `translation` cannot be resolved. Did you mean one of the following? [`comment_id`, `author`, `author_channel_id`, `text`, `like_count`, `published_at`, `updated_at`, `totalReplyCount`, `video_id`, `clean_text`].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6745/356170043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df_limited = df.limit(10000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_with_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emotions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_with_sentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3076\u001b[0m         \"\"\"\n\u001b[1;32m   3077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `translation` cannot be resolved. Did you mean one of the following? [`comment_id`, `author`, `author_channel_id`, `text`, `like_count`, `published_at`, `updated_at`, `totalReplyCount`, `video_id`, `clean_text`]."
     ]
    }
   ],
   "source": [
    "# df_limited = df.limit(10000)\n",
    "\n",
    "df_with_sentiment = df.withColumn(\"emotions\", sentiment_udf(df['translation']))\n",
    "\n",
    "df_with_sentiment.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_column = df_with_sentiment.select('emotions').limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 02:24:53 WARN TaskSetManager: Stage 2 contains a task of very large size (6407 KiB). The maximum recommended task size is 1000 KiB.\n",
      "/home/ivanseldasp/.local/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            emotions|\n",
      "+--------------------+\n",
      "|[[{score=0.953117...|\n",
      "|[[{score=0.990995...|\n",
      "|[[{score=0.988971...|\n",
      "|[[{score=0.941890...|\n",
      "|[[{score=0.986132...|\n",
      "|[[{score=0.965435...|\n",
      "|[[{score=0.984012...|\n",
      "|[[{score=0.747151...|\n",
      "|[[{score=0.990160...|\n",
      "|[[{score=0.978443...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "emotions_column.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
